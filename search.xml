<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Vcpkg 安装 OSGEarth</title>
    <url>/2024/10/18/InstallOSGEarth/</url>
    <content><![CDATA[<h2 id="OSGEarth的安装"><a href="#OSGEarth的安装" class="headerlink" title="OSGEarth的安装"></a>OSGEarth的安装</h2><p>根据能查到的博客及相关教程，分两大类方法。</p>
<ol>
<li>CMake 编译方法</li>
<li>vcpkg 安装方法</li>
</ol>
<p>笔者在使用CMake编译方法遇到了大量的问题，使用VS编译时因为第三方库的问题，始终未能成功实现编译。在花费大量的时间后，转头使用vcpkg方法完成OSGEarth及其依赖项的安装。故在此进行记录安装过程，方便后续使用。</p>
<h2 id="1-安装vcpkg"><a href="#1-安装vcpkg" class="headerlink" title="1. 安装vcpkg"></a>1. 安装vcpkg</h2><p>首先，下载vcpkg并执行 bootstrap.bat 脚本。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/microsoft/vcpkg</span><br><span class="line">.\vcpkg\bootstrap-vcpkg.bat</span><br></pre></td></tr></table></figure>
<p>vcpkg 的安装命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt;vcpkg install [packages to install]</span><br></pre></td></tr></table></figure>
<p>若您希望在 Visual Studio 中使用vcpkg，请运行以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vcpkg integrate install</span><br></pre></td></tr></table></figure>
<h2 id="2-使用vcpkg安装OSGEarth"><a href="#2-使用vcpkg安装OSGEarth" class="headerlink" title="2.使用vcpkg安装OSGEarth"></a>2.使用vcpkg安装OSGEarth</h2><p>在使用vcpkg install OSGEarth 前，确保开启GL3编译</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; [vcpkg安装目录]vcpkg\ports\osg\portfile.cmake 中</span><br><span class="line"><span class="keyword">if</span>(NOT DEFINED osg_OPENGL_PROFILEGL3)</span><br><span class="line">        <span class="built_in">set</span>(osg_OPENGL_PROFILEGL3 <span class="string">&quot;GL2&quot;</span>) //这里的GL2改为GL3</span><br><span class="line">endif()</span><br></pre></td></tr></table></figure>
<p>在vcpkg的根目录中以打开CMD，并输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vcpkg install osgearth:x64-windows</span><br></pre></td></tr></table></figure>
<p>即可完成安装，是的，只要这一行指令就可以完成安装，相比之下，CMake简直是让人吐血。vcpkg 安装OSGEarth时，会自动安装OSGEarth所需的各种依赖项。</p>
<h2 id="3-安装过程中的问题"><a href="#3-安装过程中的问题" class="headerlink" title="3.安装过程中的问题"></a>3.安装过程中的问题</h2><p>安装依赖项时，vcpkg会先查看downloads目录，没有的话会从Github上下载包。</p>
<p><img src="../images/Install1.png" alt="t"></p>
<p>在从Github上下载时会面临连接不上或者下载失败等情况，这种情况下，可以找到手动点击下载链接，将下好的包命名为目标名称。举个例子：</p>
<p><img src="../images/Install2.png" alt="t"></p>
<p>点击图中链接，保存到vcpkg下的download目录，命名为win_flex_bison-2.5.25.zip，我手动下了好几个包，一般目标名称会多一些前缀。有一些比较大的包，下载时间会比较久，要是等不及的话，也可以手动下载，不过需要重新开始指令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vcpkg install osgearth:x64-windows</span><br></pre></td></tr></table></figure>
<p>经过漫长的等待之后，OSGEarth就安装完毕了。</p>
<h2 id="4-安装完毕后"><a href="#4-安装完毕后" class="headerlink" title="4. 安装完毕后"></a>4. 安装完毕后</h2><p>在编译成功后，在cmd中输入</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vcpkg integrate install</span><br></pre></td></tr></table></figure>
<p>将vcpkg中安装的bin加入到环境变量中：</p>
<p><img src="../images/Install3.png" alt="t"></p>
<h2 id="5-测试用例"><a href="#5-测试用例" class="headerlink" title="5.测试用例"></a>5.测试用例</h2> <figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"> <span class="meta">#<span class="keyword">include</span> <span class="string">&lt;osgEarth/MapNode&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;osgEarth/TMS&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;osgEarth/EarthManipulator&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;osg/ArgumentParser&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;osgViewer/Viewer&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>** argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    osgEarth::<span class="built_in">initialize</span>();</span><br><span class="line"></span><br><span class="line">    <span class="function">osg::ArgumentParser <span class="title">args</span><span class="params">(&amp;argc, argv)</span></span>;</span><br><span class="line">    <span class="function">osgViewer::Viewer <span class="title">viewer</span><span class="params">(args)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> imagery = <span class="keyword">new</span> osgEarth::<span class="built_in">TMSImageLayer</span>();</span><br><span class="line">    imagery-&gt;<span class="built_in">setURL</span>(<span class="string">&quot;https://readymap.org/readymap/tiles/1.0.0/7/&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> mapNode = <span class="keyword">new</span> osgEarth::<span class="built_in">MapNode</span>();</span><br><span class="line">    mapNode-&gt;<span class="built_in">getMap</span>()-&gt;<span class="built_in">addLayer</span>(imagery);</span><br><span class="line"></span><br><span class="line">    viewer.<span class="built_in">setSceneData</span>(mapNode);</span><br><span class="line">    viewer.<span class="built_in">setCameraManipulator</span>(<span class="keyword">new</span> osgEarth::<span class="built_in">EarthManipulator</span>(args));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> viewer.<span class="built_in">run</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于gl.h的问题，需要加入预处理器WIN32</p>
<p><img src="../images/Install4.png" alt="t"></p>
<p> 发现出现了以下的问题：</p>
<p><img src="../images/Install5.png" alt="t"></p>
<p>这是由于一些动态链接库并没有被导入bin中</p>
<p>将下列所有的dll文件移动到你的工程文件所对应的release目录中，注意如果使用debug进行调试,需要将vcpkg中debug目录下的dll和pdb文件移动到对应debug目录中。</p>
<p><img src="../images/Install6.png" alt="t"></p>
<p>最后成功运行：</p>
<p><img src="../images/Install7.png" alt="t"></p>
<p>完结散花，欧耶！</p>
<h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6.总结"></a>6.总结</h2><p>建议使用vcpkg一步到位，CMake太折磨人了，对我来说。。。。我花了很久的时间，完成最终的安装，有点儿吐血。</p>
<p>后续有必要的话，可以下载OSGEarth源码进行学习。</p>
<h2 id="7-参考链接"><a href="#7-参考链接" class="headerlink" title="7. 参考链接"></a>7. 参考链接</h2><p><a href="https://zhuanlan.zhihu.com/p/720367150">2024 - osgEarth+vs2022最新环境配置</a><br><a href="https://huangwang.github.io/2021/07/28/Windows%E4%B8%8BOsgEarth%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/">Windows下OsgEarth编译安装过程</a><br><a href="https://docs.osgearth.org/en/latest/install.html">Getting started with osgEarth</a><br><a href="https://blog.csdn.net/m0_61776040/article/details/138897125">使用vcpkg安装osg、osgearth、osgQt</a><br><a href="https://blog.csdn.net/m0_61776040/article/details/138126419">使用cmake和vcpkg构建最新osgearth3.5</a><br><a href="https://blog.songjiahao.com/archives/1067">vcpkg安装库的导出和使用</a></p>
]]></content>
      <categories>
        <category>OSGEarth</category>
      </categories>
  </entry>
  <entry>
    <title>AI基本概念</title>
    <url>/2024/12/23/AI%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<h2 id="1-传统编程指令-vs-机器学习"><a href="#1-传统编程指令-vs-机器学习" class="headerlink" title="1.传统编程指令 vs 机器学习"></a>1.传统编程指令 vs 机器学习</h2><h3 id="传统编程"><a href="#传统编程" class="headerlink" title="传统编程"></a>传统编程</h3><p><strong>定义:</strong><br>传统编程是一种通过明确的指令和规则来告诉计算机如何完成任务的编程方式。程序员需要详细地编写每一步操作的代码，计算机会严格按照这些指令执行。</p>
<p><strong>特点:</strong></p>
<ul>
<li><strong>明确的规则:</strong> 程序员需要明确地定义每个步骤和规则。</li>
<li><strong>确定性:</strong> 给定相同的输入，程序会始终产生相同的输出。</li>
<li><strong>依赖专家知识:</strong> 需要程序员对问题领域有深入的理解，以便编写详细的逻辑和规则。</li>
</ul>
<p><strong>例子:</strong><br>假设我们要编写一个程序来判断一个数字是奇数还是偶数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">is_even</span>(<span class="params">number</span>):</span><br><span class="line">    <span class="keyword">if</span> number % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>在这个例子中，程序员明确地定义了如何判断一个数字是偶数（即数字除以2余数为0）。</p>
<h3 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h3><p><strong>定义:</strong><br>机器学习是一种通过数据训练模型，使计算机能够自动从数据中学习模式和规律的编程方式。程序员不需要明确地编写每一步操作的代码，而是通过提供大量的示例数据，让计算机自行学习。</p>
<p><strong>特点:</strong></p>
<ul>
<li><strong>数据驱动:</strong> 依赖大量的数据来训练模型。</li>
<li><strong>不确定性:</strong> 给定相同的输入，输出可能会有所不同，取决于模型的训练和随机因素。</li>
<li><strong>自动化学习:</strong> 计算机通过数据自主学习，不需要明确的规则定义。</li>
</ul>
<p><strong>例子:</strong><br>假设我们要训练一个模型来判断一张图片中是否有猫。我们可以使用一个包含大量猫和非猫图片的训练集，通过机器学习算法（如卷积神经网络）来训练模型。</p>
<p>训练集（Training Set）用于训练机器学习模型的数据集。它包含输入数据和对应的目标标签，模型通过学习这些数据中的模式和规律来调整其参数</p>
<p>测试集（Test Set）：用于评估机器学习模型性能的数据集。它包含输入数据和对应的目标标签，但这些数据在模型训练过程中是不可见的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">digits = load_digits()</span><br><span class="line">X = digits.data</span><br><span class="line">y = digits.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model = RandomForestClassifier()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">predictions = model.predict(X_test)</span><br></pre></td></tr></table></figure>
<p>在这个例子中，我们使用了一个现成的数据集和机器学习模型（随机森林分类器），通过训练数据来让模型自动学习如何分类数字。</p>
<h3 id="传统编程-vs-机器学习"><a href="#传统编程-vs-机器学习" class="headerlink" title="传统编程 vs 机器学习"></a>传统编程 vs 机器学习</h3><p><strong>1. 编程方式:</strong></p>
<ul>
<li><strong>传统编程:</strong> 程序员编写明确的规则和指令。</li>
<li><strong>机器学习:</strong> 程序员提供数据和算法，模型通过学习数据中的模式来做出决策。</li>
</ul>
<p><strong>2. 适用场景:</strong></p>
<ul>
<li><strong>传统编程:</strong> 适用于规则明确、逻辑清晰的问题，如计算公式、数据处理等。</li>
<li><strong>机器学习:</strong> 适用于规则复杂、难以明确定义的问题，如图像识别、语音识别、推荐系统等。</li>
</ul>
<p><strong>3. 处理方式:</strong></p>
<ul>
<li><strong>传统编程:</strong> 需要详细的步骤和逻辑，依赖人类专家的知识。</li>
<li><strong>机器学习:</strong> 依赖大量数据，通过学习数据中的模式和规律来做出决策。</li>
</ul>
<h2 id="2-自然语言（NL）"><a href="#2-自然语言（NL）" class="headerlink" title="2.自然语言（NL）"></a>2.自然语言（NL）</h2><h3 id="自然语言处理（NLP）"><a href="#自然语言处理（NLP）" class="headerlink" title="自然语言处理（NLP）"></a>自然语言处理（NLP）</h3><p><strong>定义:</strong><br>自然语言处理（Natural Language Processing, NLP）是计算机科学和人工智能的一个子领域，致力于实现计算机对人类语言的理解、解读和生成。NLP涵盖了从文本处理到语音识别的广泛任务。</p>
<p><strong>例子:</strong></p>
<ul>
<li><strong>文本分类:</strong> 电子邮件过滤系统可以使用NLP来自动将邮件分类为“垃圾邮件”或“非垃圾邮件”。</li>
<li><strong>情感分析:</strong> 社交媒体监控工具可以使用NLP来分析用户评论的情感倾向（正面、负面或中性）。</li>
</ul>
<h3 id="自然语言理解（NLU）"><a href="#自然语言理解（NLU）" class="headerlink" title="自然语言理解（NLU）"></a>自然语言理解（NLU）</h3><p><strong>定义:</strong><br>自然语言理解（Natural Language Understanding, NLU）是NLP的一个子领域，专注于使计算机能够理解和解释人类语言的含义。NLU涉及语义分析、意图识别、实体识别等任务。</p>
<p><strong>例子:</strong></p>
<ul>
<li><strong>意图识别:</strong> 在智能语音助手中，当用户说“帮我订一张明天去纽约的机票”，系统需要识别用户的意图是“订票”。</li>
<li><strong>实体识别:</strong> 在同一句话中，系统需要识别出“纽约”是一个地名，“明天”是一个时间表达。</li>
</ul>
<h3 id="自然语言生成（NLG）"><a href="#自然语言生成（NLG）" class="headerlink" title="自然语言生成（NLG）"></a>自然语言生成（NLG）</h3><p><strong>定义:</strong><br>自然语言生成（Natural Language Generation, NLG）是NLP的另一个子领域，旨在使计算机能够生成自然、人类可读的语言文本。NLG通常用于自动报告生成、内容创作等场景。</p>
<p><strong>例子:</strong></p>
<ul>
<li><strong>自动报告:</strong> 金融分析工具可以使用NLG来生成每日或每周的市场分析报告。</li>
<li><strong>内容创作:</strong> 新闻自动写作系统可以根据输入的数据生成新闻文章，如体育比赛的赛后报道。</li>
</ul>
<h3 id="通俗易懂的例子"><a href="#通俗易懂的例子" class="headerlink" title="通俗易懂的例子"></a>通俗易懂的例子</h3><p>假设我们有一个智能语音助手（如Siri或Alexa），以下是NLP、NLU和NLG在其中的具体应用：</p>
<ol>
<li><strong>用户输入:</strong> 用户说：“明天的天气怎么样？”</li>
<li><strong>自然语言处理（NLP）:</strong> <ul>
<li><strong>语音识别:</strong> 首先将用户的语音转换为文本：“明天的天气怎么样？”</li>
<li><strong>文本预处理:</strong> 清理和规范化文本，如去除多余的空格或标点。</li>
</ul>
</li>
<li><strong>自然语言理解（NLU）:</strong> <ul>
<li><strong>意图识别:</strong> 系统识别用户的意图是询问天气。</li>
<li><strong>实体识别:</strong> 系统识别出“明天”是时间相关的实体。</li>
</ul>
</li>
<li><strong>数据处理:</strong> 系统查询天气数据库，获取“明天”的天气信息。</li>
<li><strong>自然语言生成（NLG）:</strong> <ul>
<li><strong>生成文本:</strong> 系统将查询结果转换为自然语言文本：“明天的天气是晴天，最高气温25度，最低气温15度。”</li>
<li><strong>语音合成:</strong> 将生成的文本转换为语音，并播放给用户。</li>
</ul>
</li>
</ol>
<p>通过这个例子，可以看到NLP、NLU和NLG如何协同工作来实现一个完整的自然语言交互过程。</p>
<h2 id="3-监督学习（Supervised-Learning）"><a href="#3-监督学习（Supervised-Learning）" class="headerlink" title="3.监督学习（Supervised Learning）"></a>3.监督学习（Supervised Learning）</h2><p>监督学习是一种机器学习方法，模型通过已知的输入和输出数据进行训练，直到模型能够准确地匹配输入和输出的关系。</p>
<h3 id="分类（Classification）"><a href="#分类（Classification）" class="headerlink" title="分类（Classification）"></a>分类（Classification）</h3><p>分类任务是将输入数据分为离散的类别。</p>
<ul>
<li><strong>例子</strong>：垃圾邮件过滤。给定一封电子邮件，模型需要判断这封邮件是垃圾邮件（spam）还是正常邮件（ham）。</li>
</ul>
<h3 id="回归（Regression）"><a href="#回归（Regression）" class="headerlink" title="回归（Regression）"></a>回归（Regression）</h3><p>回归任务是预测连续的数值输出。</p>
<ul>
<li><strong>例子</strong>：房价预测。根据特征（如房子的面积、位置等），模型预测房子的价格。</li>
</ul>
<h3 id="关联规则（Association-Rule）"><a href="#关联规则（Association-Rule）" class="headerlink" title="关联规则（Association Rule）"></a>关联规则（Association Rule）</h3><p>关联规则是寻找数据中不同项之间的关系或模式。</p>
<ul>
<li><strong>例子</strong>：购物篮分析。超市可以通过关联规则发现哪些商品常常一起被购买，比如“如果顾客买了面包和黄油，他们也很可能会买牛奶”。</li>
</ul>
<h2 id="4-无监督学习（Unsupervised-Learning）"><a href="#4-无监督学习（Unsupervised-Learning）" class="headerlink" title="4.无监督学习（Unsupervised Learning）"></a>4.无监督学习（Unsupervised Learning）</h2><p>无监督学习是一种机器学习方法，模型在没有标签数据（即没有输入和输出配对）的情况下，通过数据内部的结构进行学习。</p>
<h3 id="聚类（Clustering）"><a href="#聚类（Clustering）" class="headerlink" title="聚类（Clustering）"></a>聚类（Clustering）</h3><p>聚类任务是将数据分成不同的组，每个组中的数据项彼此相似。</p>
<ul>
<li><strong>例子</strong>：客户细分。根据购买行为的数据，商业可以将客户分成不同的群体，比如“大宗购买者”、“偶尔购买者”等。</li>
</ul>
<h2 id="5-强化学习（Reinforcement-Learning）"><a href="#5-强化学习（Reinforcement-Learning）" class="headerlink" title="5.强化学习（Reinforcement Learning）"></a>5.强化学习（Reinforcement Learning）</h2><p>强化学习是一种机器学习方法，其中一个 <strong>智能体（Agent）</strong> 通过与 <strong>环境（Environment）</strong> 互动，以试错的方式学习如何完成任务或达到目标。</p>
<h3 id="核心概念："><a href="#核心概念：" class="headerlink" title="核心概念："></a>核心概念：</h3><ol>
<li><strong>状态（States）</strong>：状态是对当前环境的一种描述。在任何时刻，智能体所处的状态反映了当前的环境情况。<ul>
<li><strong>例子</strong>：在一个迷宫游戏中，状态可以是智能体当前所在的位置；在围棋中，状态就是棋盘上每颗棋子的布局。</li>
</ul>
</li>
<li><strong>奖励（Reward）</strong>：奖励是对智能体在某个状态下采取某个动作后的反馈，它可以是正的（奖励）或负的（惩罚）。<ul>
<li><strong>例子</strong>：在迷宫游戏中，如果智能体走到正确的方向，可以获得正的奖励（例如+10分）；如果撞到墙壁，可能会获得负的奖励（例如-10分）。</li>
</ul>
</li>
<li><strong>智能体（Agent）</strong>：智能体是执行动作并接收奖励的决策者。智能体通过不断地选择动作来改变其状态，从而尝试最大化累计奖励。<ul>
<li><strong>例子</strong>：在自动驾驶汽车中，智能体就是控制汽车行驶的算法；在游戏中，智能体就是玩家控制的角色或者对手AI。</li>
</ul>
</li>
</ol>
<h3 id="强化学习的过程："><a href="#强化学习的过程：" class="headerlink" title="强化学习的过程："></a>强化学习的过程：</h3><ol>
<li><strong>观察</strong>：智能体观察当前的状态。</li>
<li><strong>选择动作</strong>：根据当前状态，智能体选择一个动作。这个动作可能基于之前的学习，也可能是一个随机选择。</li>
<li><strong>执行动作</strong>：智能体执行所选择的动作，环境随之发生改变。</li>
<li><strong>获取反馈</strong>：环境向智能体提供执行该动作后的新状态及即时奖励。</li>
<li><strong>更新策略</strong>：智能体根据奖励更新其策略，使其在未来选择更优的动作，以获得更多的累计奖励。</li>
</ol>
<h3 id="一个简单的例子："><a href="#一个简单的例子：" class="headerlink" title="一个简单的例子："></a>一个简单的例子：</h3><h4 id="玩具汽车学习走迷宫"><a href="#玩具汽车学习走迷宫" class="headerlink" title="玩具汽车学习走迷宫"></a>玩具汽车学习走迷宫</h4><ol>
<li><strong>状态（States）</strong>：玩具汽车在迷宫中的位置，例如（2, 3）代表在迷宫中第二行第三列的位置。</li>
<li><strong>动作（Actions）</strong>：玩具汽车可以前进的方向，例如上、下、左、右。</li>
<li><strong>奖励（Reward）</strong>：如果玩具汽车朝着出口前进，它获得一个正的奖励（+10分）；如果撞到死胡同或墙，则获得负的奖励（-10分）。</li>
<li><strong>智能体（Agent）</strong>：控制玩具汽车的AI</li>
</ol>
<h4 id="学习过程："><a href="#学习过程：" class="headerlink" title="学习过程："></a>学习过程：</h4><ol>
<li>玩具汽车在迷宫的某个位置开始（初始状态）。</li>
<li>汽车根据当前状态选择一个方向行驶（例如向右）。</li>
<li>汽车驾驶，位置发生变化（新状态），并根据新状态获得奖励（例如没有撞墙，获得+1分）。</li>
<li>AI 根据奖励更新其策略，逐渐学习在迷宫中如何移动才能尽快找到出口。</li>
</ol>
<p>通过这种试错和不断优化策略的过程，玩具汽车最终会形成一套有效的行为策略，使其能够成功找到迷宫的出口，同时避免无效的或有害的动作。</p>
<p>总结来说，强化学习通过不断试验和从环境中获得反馈，让智能体逐渐学会在不同的状态下采取最佳的行动，以获得最大的累计奖励。机器学习模型的效果评估是确保模型能够在不同的数据集上准确预测的重要步骤。在理解这个评估过程中，有三个关键概念：欠拟合、最佳拟合和过拟合。</p>
<h2 id="6-机器学习效果评估"><a href="#6-机器学习效果评估" class="headerlink" title="6.机器学习效果评估"></a>6.机器学习效果评估</h2><h3 id="欠拟合-Under-fitting"><a href="#欠拟合-Under-fitting" class="headerlink" title="欠拟合 (Under-fitting)"></a>欠拟合 (Under-fitting)</h3><p>欠拟合是指模型过于简单，无法捕捉到训练数据中的模式和特征，导致在训练数据和新数据上的表现都很差。</p>
<h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><ul>
<li><strong>简单例子</strong>：想象一下你用一条直线来拟合一个明显是曲线的散点图。如果数据点分布成一个“U”形，而你只用一条直线来拟合，就会错过大部分数据的特征，导致欠拟合。</li>
<li><strong>实际例子</strong>：在房价预测问题中，你只用房子的面积一个特征来预测价格，而忽略了位置、房龄、装修等重要特征，导致模型无法准确预测房价。</li>
</ul>
<h3 id="最佳拟合-Optimal-fitting"><a href="#最佳拟合-Optimal-fitting" class="headerlink" title="最佳拟合 (Optimal-fitting)"></a>最佳拟合 (Optimal-fitting)</h3><p>最佳拟合是指模型恰当地捕捉到了训练数据中的模式和特征，同时也能很好地应用于新数据。这种情况下，模型在训练数据和测试数据上都有良好的表现。</p>
<h4 id="例子-1"><a href="#例子-1" class="headerlink" title="例子"></a>例子</h4><ul>
<li><strong>简单例子</strong>：你用一条适当的二次曲线（抛物线）来拟合一个“U”形的散点图，曲线能够很好地通过大部分数据点，这是最佳拟合的状态。</li>
<li><strong>实际例子</strong>：在房价预测问题中，你考虑了多个重要特征（如面积、位置、房龄、装修等），模型能够准确预测训练数据中的房价，并在新数据上表现也很好。</li>
</ul>
<h3 id="过拟合-Over-fitting"><a href="#过拟合-Over-fitting" class="headerlink" title="过拟合 (Over-fitting)"></a>过拟合 (Over-fitting)</h3><p>过拟合是指模型过于复杂，过度地记住了训练数据中的每一个细节和噪声，从而失去了对新数据的泛化能力。过拟合的模型在训练数据上表现很好，但在新数据上表现较差。</p>
<h4 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h4><ul>
<li><strong>简单例子</strong>：你用一条非常复杂的高次多项式曲线来拟合一个“U”形的散点图，这条曲线几乎精确地通过每个数据点，但实际数据通常带有噪声，在新数据上，复杂曲线就不再适用。</li>
<li><strong>实际例子</strong>：在房价预测问题中，你不仅使用了面积、位置、房龄、装修等特征，还加入了一些不相关的特征（如前几天是否下过雨），模型在训练数据上表现非常好，但在新数据上预测效果很差。</li>
</ul>
<h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><ol>
<li><strong>欠拟合 (Under-fitting)</strong>：模型太简单，不能很好地捕捉数据中的模式。<ul>
<li><strong>简单例子</strong>：用直线拟合“U”形数据。</li>
<li><strong>实际例子</strong>：房价预测中只用面积一个特征。</li>
</ul>
</li>
<li><strong>最佳拟合 (Optimal-fitting)</strong>：模型恰到好处，既能很好地拟合训练数据，也能对新数据有良好表现。<ul>
<li><strong>简单例子</strong>：用合适的二次曲线拟合“U”形数据。</li>
<li><strong>实际例子</strong>：房价预测中使用了多个重要特征。</li>
</ul>
</li>
<li><strong>过拟合 (Over-fitting)</strong>：模型太复杂，过度记住了训练数据，无法泛化到新数据。<ul>
<li><strong>简单例子</strong>：用复杂的高次多项式拟合“U”形数据，过度拟合了每个数据点。</li>
<li><strong>实际例子</strong>：房价预测中加入了很多不相关特征，结果在新数据上效果不好。</li>
</ul>
</li>
</ol>
<p>总之，目标是找到让模型最佳拟合训练数据和测试数据的平衡点，既不过于简单也不过于复杂。</p>
<h2 id="7-深度学习"><a href="#7-深度学习" class="headerlink" title="7.深度学习"></a>7.深度学习</h2><p>深度学习是机器学习的一个重要分支，它突破了传统机器学习算法的瓶颈，在多个研究与应用领域取得了重大进展。</p>
<div style="text-align: center;">
  <img src="/2024/12/23/AI%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/AI基本概念\机器学习算法.png" width="60%" alt="机器学习算法">
</div>

<p>深度学习是指通过构建多层神经网络结构来学习数据的特征，以便于进行数据分类、回归与生成。与浅层学习相比，神经网络结构的层数更多（一般大于或等于4层），通过多层神经网络结构可以学习得到更丰富的数据特征。在理解深度学习时，我们需要了解神经网络的三种关键层：输入层（Input Layer）、隐藏层（Hidden Layer）和输出层（Output Layer）。</p>
<div style="text-align: center;">
  <img src="/2024/12/23/AI%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/AI基本概念\多层前馈网络.png" width="60%" alt="机器学习算法">
</div>

<h3 id="输入层-Input-Layer"><a href="#输入层-Input-Layer" class="headerlink" title="输入层 (Input Layer)"></a>输入层 (Input Layer)</h3><p><strong>输入层</strong>是神经网络的第一个层，它接收原始的数据输入。这些输入可以是图像的像素值、文本的词向量或其他形式的数据。输入层的节点（或神经元）数目取决于输入数据的特征数。</p>
<h4 id="例子：-1"><a href="#例子：-1" class="headerlink" title="例子："></a>例子：</h4><ul>
<li><strong>图像分类</strong>：如果你有一张28x28像素的灰度图像作为输入，输入层将有28×28=784个节点，每个节点代表一个像素值。</li>
<li><strong>房价预测</strong>：如果你有五个特征（如面积、位置、房龄等），输入层将有5个节点，每个节点代表一个特征值。</li>
</ul>
<h3 id="隐藏层-Hidden-Layer"><a href="#隐藏层-Hidden-Layer" class="headerlink" title="隐藏层 (Hidden Layer)"></a>隐藏层 (Hidden Layer)</h3><p><strong>隐藏层</strong>位于输入层和输出层之间，负责对输入数据进行特征提取和变换。隐藏层可以有一层或多层，称为“深度”正是因为有许多隐藏层。每个隐藏层通过与前一层和后一层的连接（权重和偏置）来传递信息。</p>
<h4 id="例子：-2"><a href="#例子：-2" class="headerlink" title="例子："></a>例子：</h4><ul>
<li><strong>图像分类</strong>：何将28x28像素的输入映射到更加抽象的特征层，如第一层可能识别边缘，第二层可能识别更复杂的形状。</li>
<li><strong>房价预测</strong>：隐藏层可以捕捉输入特征的复杂非线性关系，帮助模型准确预测房价。</li>
</ul>
<h3 id="输出层-Output-Layer"><a href="#输出层-Output-Layer" class="headerlink" title="输出层 (Output Layer)"></a>输出层 (Output Layer)</h3><p><strong>输出层</strong>是神经网络的最后一层，它给出模型的最终预测结果。输出层的节点数目和类型取决于具体的任务。</p>
<h4 id="例子：-3"><a href="#例子：-3" class="headerlink" title="例子："></a>例子：</h4><ul>
<li><strong>图像分类</strong>：如果你要把图像分类为10个类别（如手写数字0-9），输出层将有10个节点，每个节点代表一个类别的概率。</li>
<li><strong>房价预测</strong>：如果你需要预测房价，输出层将有一个节点，它输出房价的预测值。</li>
</ul>
<h3 id="综合例子："><a href="#综合例子：" class="headerlink" title="综合例子："></a>综合例子：</h3><h4 id="任务：图像分类"><a href="#任务：图像分类" class="headerlink" title="任务：图像分类"></a>任务：图像分类</h4><ol>
<li><strong>输入层</strong>：假设我们分类的是28x28像素的手写数字图像。<ul>
<li><strong>输入层节点数</strong>：784个节点，每个节点对应一个像素值。</li>
</ul>
</li>
<li><strong>隐藏层</strong>：假设有两层隐藏层。<ul>
<li><strong>第一隐藏层</strong>：提取简单特征（如边缘），设有128个节点。</li>
<li><strong>第二隐藏层</strong>：提取更复杂的特征（如更高层次的形状），设有64个节点。</li>
</ul>
</li>
<li><strong>输出层</strong>：假设分类为10个类别（数字0到9）。<ul>
<li><strong>输出层节点数</strong>：10个节点，每个节点代表图像属于某个数字类别的概率。</li>
</ul>
</li>
</ol>
<h4 id="任务：房价预测"><a href="#任务：房价预测" class="headerlink" title="任务：房价预测"></a>任务：房价预测</h4><ol>
<li><strong>输入层</strong>：假设预测房价时用五个特征：面积、位置、房龄、房型、市场状况。<ul>
<li><strong>输入层节点数</strong>：5个节点，每个节点代表一个特征。</li>
</ul>
</li>
<li><strong>隐藏层</strong>：假设有一层隐藏层。<ul>
<li><strong>隐藏层</strong>：捕捉输入特征之间的复杂关系，设有10个节点。</li>
</ul>
</li>
<li><strong>输出层</strong>：输出预测的房价。<ul>
<li><strong>输出层节点数</strong>：1个节点，表示预测的房价。</li>
</ul>
</li>
</ol>
<p>简而言之：</p>
<ol>
<li><strong>输入层</strong>：接收原始数据。</li>
<li><strong>隐藏层</strong>：提取和转换输入数据的特征。</li>
<li><strong>输出层</strong>：给出预测结果。</li>
</ol>
<p>通过这些层的协同工作，神经网络能够从原始数据中学习模式，并对新数据进行准确的预测或分类。神经网络（Neural Network）是模仿人脑工作原理的一种算法，由多个互相连接的节点（也叫神经元）组成。这些节点被组织成不同的层，通过层与层之间的连接和权重调整来处理数据。</p>
<h2 id="8-神经网络"><a href="#8-神经网络" class="headerlink" title="8.神经网络"></a>8.神经网络</h2><h3 id="神经网络的基本概念："><a href="#神经网络的基本概念：" class="headerlink" title="神经网络的基本概念："></a>神经网络的基本概念：</h3><ol>
<li><strong>节点（Neuron）</strong>：类似于人脑中的神经元，每个节点接收输入信号，进行处理后发送输出信号。</li>
<li><strong>层（Layer）</strong>：神经网络的结构由多个层组成，每层包含一定数量的节点。一般分为输入层、隐藏层和输出层。</li>
<li><strong>连接（Weights）</strong>：每两个相邻层之间的节点通过带有权重的连接相连，这些权重决定了信号传输的强度。</li>
</ol>
<h3 id="浅层神经网络（Shallow-Neural-Networks）"><a href="#浅层神经网络（Shallow-Neural-Networks）" class="headerlink" title="浅层神经网络（Shallow Neural Networks）"></a>浅层神经网络（Shallow Neural Networks）</h3><p>浅层神经网络是指包含少量隐藏层（通常只有一个隐藏层）的一种神经网络。由于层数较少，计算相对简单，适用于一些较简单或较小规模的任务。</p>
<h4 id="例子：-4"><a href="#例子：-4" class="headerlink" title="例子："></a>例子：</h4><ul>
<li><strong>任务：二分类问题</strong>（如垃圾邮件识别）<ul>
<li><strong>输入层</strong>：接收邮件的特征（如文本词频等）。</li>
<li><strong>隐藏层</strong>：只有一层隐藏层，包含若干节点。</li>
<li><strong>输出层</strong>：输出是两个节点，表示垃圾邮件或正常邮件的概率。</li>
</ul>
</li>
</ul>
<p>浅层神经网络虽然简单，但在某些简单任务上表现不俗。例如在垃圾邮件识别时，简单的特征如特定词汇的频率就能较好地区分垃圾邮件。</p>
<h3 id="深度神经网络（Deep-Neural-Networks）"><a href="#深度神经网络（Deep-Neural-Networks）" class="headerlink" title="深度神经网络（Deep Neural Networks）"></a>深度神经网络（Deep Neural Networks）</h3><p>深度神经网络则包含多个隐藏层，层数较多，使其能够捕捉数据的复杂模式和高级特征。深度神经网络被用来处理更复杂、规模更大的任务，比如图像识别、自驾车、自然语言处理等。</p>
<h4 id="例子：-5"><a href="#例子：-5" class="headerlink" title="例子："></a>例子：</h4><ul>
<li><strong>任务：图像分类</strong>（如手写数字识别）<ul>
<li><strong>输入层</strong>：接收图像的像素值（比如28x28的灰度图像，有784个输入节点）。</li>
<li><strong>多个隐藏层</strong>：每个层逐步提取图像的不同特征，比如边缘、形状和更复杂的模式。可能包含若干层，每层有大量节点。</li>
<li><strong>输出层</strong>：输出是多个节点（比如10个节点），每个节点表示图像属于某个类别（如数字0-9）的概率。</li>
</ul>
</li>
</ul>
<p>深度神经网络由于其多层结构，能够逐级提取更复杂的特征。例如在图像分类任务中，底层隐藏层可能识别简单的边缘特征，中间层可能识别复杂的形状特征，顶层隐藏层则综合所有特征完成最终的分类任务。</p>
<h3 id="总结：-1"><a href="#总结：-1" class="headerlink" title="总结："></a>总结：</h3><ol>
<li><strong>浅层神经网络（Shallow Neural Networks）</strong><ul>
<li>结构：通常只有一个隐藏层。</li>
<li>适用任务：简单、规模较小的任务。</li>
<li><strong>例子</strong>：垃圾邮件识别。</li>
<li><strong>优势</strong>：计算简单，训练时间短。</li>
</ul>
</li>
<li><strong>深度神经网络（Deep Neural Networks）</strong><ul>
<li>结构：包含多个隐藏层。</li>
<li>适用任务：复杂、规模较大的任务。</li>
<li><strong>例子</strong>：图像分类、自驱动汽车。</li>
<li><strong>优势</strong>：能够提取复杂的高级特征，更适用于复杂的问题。</li>
</ul>
</li>
</ol>
<p>通过这个简单的区分，深度神经网络和浅层神经网络的差异主要体现在隐藏层的数量和数据处理能力上。浅层神经网络适合简单任务，而深度神经网络则在处理复杂任务时表现更为强大。</p>
<h2 id="9-CNN（卷积神经网络）"><a href="#9-CNN（卷积神经网络）" class="headerlink" title="9.CNN（卷积神经网络）"></a>9.CNN（卷积神经网络）</h2><p>卷积神经网络（CNN）是一种特别设计用来处理具有类似网格结构的数据的深度学习模型，例如图像（本质上是像素的矩阵）。在最简单的术语中，CNN通过模拟我们人类的视觉系统工作来帮助计算机“看懂”图像或其他类似数据。</p>
<div style="text-align: center;">
  <img src="/2024/12/23/AI%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/AI基本概念\CNN.png" width="80%" alt="机器学习算法">
</div>
典型的卷积神经网络一般由卷积层（含激活函数）、池化层、全连接层和输出层构成，其中卷积层与池化层一般交替排列，之后接一层或者多层全连接层，最后是输出层。

<div style="text-align: center;">
  <img src="/2024/12/23/AI%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/AI基本概念\CNN结构.png" width="100%" alt="机器学习算法">
</div>

<p>卷积运算：给定二维图像𝑰与二维卷积核𝑲，我们将其看作矩阵，根据上述二维离散卷积运算公式，图像𝑰与卷积核𝑲的卷积运算可表示为：</p>
<div style="text-align: center;">
  <img src="/2024/12/23/AI%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/AI基本概念\CNN卷积.png" width="60%" alt="机器学习算法">
</div>

<p>要理解CNN，我们可以通过如何处理图像的任务来进行说明：</p>
<h3 id="卷积层（Convolutional-Layer）："><a href="#卷积层（Convolutional-Layer）：" class="headerlink" title="卷积层（Convolutional Layer）："></a>卷积层（Convolutional Layer）：</h3><p>卷积核相当于传统计算机视觉领域中的特征算子，用于提取图像特征。</p>
<div style="text-align: center;">
  <img src="/2024/12/23/AI%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/AI基本概念\卷积核.png" width="50%" alt="机器学习算法">
</div>

<blockquote>
<p>假设你有一张纸上画着各种形状（如圆形、方形等）。你用一个小镜子（这就是所谓的“滤镜”或“卷积核”）来观察这张纸。每次你只能看到镜子中的一小部分图形。根据这部分，你尝试猜测这是哪种形状。移动镜子到纸上的不同部位，重复这个观察过程，最终你可以获得关于图形的不同信息。在CNN中，这个“小镜子”观察的过程就是“卷积操作”，它可以帮助模型捕捉到图像中的基本特征（如边缘、角点等）。</p>
</blockquote>
<h3 id="池化层（Pooling-Layer）："><a href="#池化层（Pooling-Layer）：" class="headerlink" title="池化层（Pooling Layer）："></a>池化层（Pooling Layer）：</h3><p>池化操作使用某位置相邻输出的总体统计特征作为该位置的输出，常用最大池化（max-pooling）和均值池化（average-pooling）。池化层不包含需要训练学习的参数，仅需指定池化操作的核大小、步幅以及池化类型。</p>
<div style="text-align: center;">
  <img src="/2024/12/23/AI%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/AI基本概念\池化.png" width="50%" alt="机器学习算法">
</div>

<blockquote>
<p>接下来，如果你想让镜子中看到的图像部分更抽象、更容易总结（即减小它的尺寸），你可能会选择在画好的图形上用较大的格子遮住一些部分，只保留某些重要的特征（比如形状的特定部分）。这个过程类似于“池化”，它有助于降低处理的数据量和抓取最显著的特征。</p>
</blockquote>
<h3 id="全连接层（Fully-Connected-Layer）："><a href="#全连接层（Fully-Connected-Layer）：" class="headerlink" title="全连接层（Fully Connected Layer）："></a>全连接层（Fully Connected Layer）：</h3><p>最后，将你的所有观察结果放在一起，尝试根据你提取的信息来完整地识别纸上的整个图形。在CNN中，这个汇总过程是通过“全连接层”完成的，它基于前面提取到的所有特徥做出最终的判断和分类。</p>
<h3 id="例子：-6"><a href="#例子：-6" class="headerlink" title="例子："></a>例子：</h3><blockquote>
<p>想象在一个自动分拣系统中，系统需要区分苹果、梨和橙子。CNN通过学习这三种水果的卷积图像特征（如颜色、形状等），在卷积层捕捉这些特征，在池化层精化并简化特征，在全连接层做出最终判断。这样，当下次系统看到一个新的水果图像时，它可以通过这些学到的特征来识别和分类。</p>
</blockquote>
<p>总的来说，CNN通过模拟观察和结构化处理来理解图像，类似于我们通过看不同部分来理解一个完整画面的方式。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ol>
<li><p>卷积层的作用</p>
<ul>
<li>浅层卷积层：提取的是图像基本特征，如边缘、方向和纹理等特征。</li>
<li>深层卷积层：提取的是图像高阶特征，出现了高层语义模式， 如“车轮”、“人脸”等特征。</li>
</ul>
</li>
<li><p>池化层的作用</p>
<ul>
<li>对输入对象进行“降采样（Downsampling）”操作，一定程度上提高了模型的容错能力</li>
<li>保证了当输入出现少量平移时，输出近似不变，增强了网络对输入图像中的小变形、扭曲、平移的鲁棒性(输入里的微小扭曲不会改变池化输出）</li>
<li>池化核的指定相当于在空间范围内对特征图的特征进行了维度约减，同时缩小了下一层输入的特征图尺寸，进而在一定程度上减少了网络的参数个数和计算量。</li>
</ul>
</li>
<li>全连接层的作用<ul>
<li>全连接层一般由一到多层的全连接神经网络组成，功能是对卷积层或池化层输出的特征图（二维）进行降维。</li>
<li>可以将不同的区域特征合并为一个完整的特征</li>
</ul>
</li>
</ol>
<h2 id="10-RNN（循环神经网络"><a href="#10-RNN（循环神经网络" class="headerlink" title="10.RNN（循环神经网络)"></a>10.RNN（循环神经网络)</h2><p>循环神经网络（RNN）是一种专为处理序列数据（如文字、语音或任何连续的时间数据）而设计的神经网络。与传统的神经网络不同，RNN能够处理输入之间的时间动态关系，使其特别适<br>用于那些需要理解时间序列数据或上下文信息的场景。</p>
<p>循环神经网络（Recurrent Neural Network，RNN）是一类具有短期记忆能力的神经网络．在循环神经网络中，神经元不但可以接受其他神经元的信息，也可以接受自身的信息，形成具有环路的网络结构．和前馈神经网络相比，循环神经网络更加符合生物神经网络的结构．</p>
<h3 id="基本工作原理："><a href="#基本工作原理：" class="headerlink" title="基本工作原理："></a>基本工作原理：</h3><blockquote>
<p>想象你在看一部电影，并且你想要随时预测接下来会发生什么。每经过一段电影，你都会根据目前为止看到的内容（而不只是最近几分钟的内容）来更新你的预测。RNN的工作方式与此类似：它记住之前发生的事情，并使用这些信息来帮助作出当前的决策。RNN内部有所谓的“循环”，这使得过去的信息能够影响当前的输出。</p>
</blockquote>
<h3 id="如何理解RNN："><a href="#如何理解RNN：" class="headerlink" title="如何理解RNN："></a>如何理解RNN：</h3><ol>
<li><strong>记忆功能</strong>：你可以将RNN想象为有记忆的网络，它不仅看当前的输入（比如现在的字或词），而且还“记得”它之前处理过的信息。</li>
<li><strong>参数共享</strong>：在处理序列的每一步时，RNN重复使用同一套参数（权重和偏置）。这不仅使得模型更加紧凑，而且还可以处理任意长度的序列。</li>
<li><strong>输出依赖</strong>：根据应用，RNN可以在任何时间点生成输出，或者在处理完所有输入后才产生一个输出。这意味着它可以被用来做分类（比如判断一句话的情感）、生成连续的数据（如文本生成）等。</li>
</ol>
<h3 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h3><ol>
<li><strong>语言模型</strong>：假设你要预测一句话中下一个词是什么。RNN通过读取目前为止的句子（单词的序列），根据上下文预测下一个单词。比如，在“晚饭后我们去”之后，RNN可能会预测“散步”作为下一个词。</li>
<li><strong>股票价格预测</strong>：给定一个股票过去的价格序列，RNN可以预测未来的价格变动。它通过分析价格随时间变化的趋势，来做出未来的预估。</li>
<li><strong>手写文本识别</strong>：当你写字时，每一个字符与前一个字符都有关联。RNN能够分析字符序列，并帮助识别整个单词或句子。</li>
</ol>
<p>总结来说，RNN通过其内部的循环连接，能够保留信息的流动，这使它非常适用于那些需要考虑时间连续性或输入之间关系的任务。这种“记忆功能”使得RNN在自然语言处理、时间序列分析等领域表现出色。</p>
<p>RNN（循环神经网络）由输入层、隐藏层和输出层组成，每一层都担任不同的角色。通过一个简单的例子，我们可以更好地理解这些层在RNN中的功能。</p>
<div style="text-align: center;">
  <img src="/2024/12/23/AI%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/AI基本概念\RNN.png" width="40%" alt="机器学习算法">
</div>

<h3 id="输入层"><a href="#输入层" class="headerlink" title="输入层"></a>输入层</h3><p>这一层的任务是接收序列中的每个元素（例如，一个句子中的单词或时间序列数据中的一个时间点）。假设我们的任务是进行文本情感分析，并且输入是一句话中的每个词。每个词首先被转化为数字形式（通常是向量，通过词嵌入技术如Word2Vec或GloVe实现），然后送入RNN。</p>
<h4 id="例子：-7"><a href="#例子：-7" class="headerlink" title="例子："></a>例子：</h4><p>在处理句子：“我爱自然语言处理”时，每个词（例如“我”、“爱”、“自然”、“语言”、“处理”）依次被转换为向量，并输入到网络中。</p>
<h3 id="隐藏层"><a href="#隐藏层" class="headerlink" title="隐藏层"></a>隐藏层</h3><p>隐藏层是RNN的核心，它负责处理输入并保留先前输入的信息。隐藏层中的节点会对当前输入和前一个时间步的隐藏状态进行处理，生成新的隐藏状态，这个过程会不断循环。这使得网络能够从数据的序列中“记住”信息，并用这些信息影响后续的输出。</p>
<h4 id="例子：-8"><a href="#例子：-8" class="headerlink" title="例子："></a>例子：</h4><p>继续上面的情感分析的例子，当单词“我”输入后，隐藏层更新其状态。当下一个词“爱”输入时，隐藏层不只是考虑“爱”，而是结合之前的状态（已经处理了“我”）来更新状态。这个状态现在包含了“我爱”的信息，以此类推。</p>
<h3 id="输出层"><a href="#输出层" class="headerlink" title="输出层"></a>输出层</h3><p>在序列的每一步或最后一步（取决于特定的应用），输出层会基于隐藏层的最终状态生成输出。输出可以是一个类别标签（如在分类任务中），一个连续值（如在回归任务中），或者是下一个序列元素（如在预测任务中）。</p>
<h3 id="训练算法：BPTT"><a href="#训练算法：BPTT" class="headerlink" title="训练算法：BPTT"></a>训练算法：BPTT</h3><p>BPTT算法是针对循环层的训练算法，它的基本原理和BP算法是一样的，也包含同样的三个步骤：</p>
<ol>
<li>前向计算每个神经元的输出值；</li>
<li>反向计算每个神经元的误差项值，它是误差函数E对神经元j的加权输入的偏导数；</li>
<li>计算每个权重的梯度。<br>最后再用随机梯度下降算法更新权重。</li>
</ol>
<h4 id="例子：-9"><a href="#例子：-9" class="headerlink" title="例子："></a>例子：</h4><blockquote>
<p>在情感分析例子中，输出层可能在处理完整个句子后评估整个句子的情感倾向，并输出是积极、中立还是消极的情绪标签。</p>
</blockquote>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过输入层接收并转换数据，隐藏层处理并“记忆”序列中的信息，最后输出层根据隐藏层的信息作出决策，RNN能够有效地处理序列数据。这种结构使得RNN在语言模型、股票预浔、语音识别等众多需要理解序列数据的上下文的任务中表现优异。</p>
<h2 id="11-Transformer"><a href="#11-Transformer" class="headerlink" title="11.Transformer"></a>11.Transformer</h2><p>Transformer 是一种深度学习模型，于 2017 年被引入，主要用于处理序列数据如文本。它在处理诸如翻译或文本生成等语言理解任务时表现出了卓越的效果。Transformer 的核心优势在于其能同时处理输入序列的所有部分，这大大加快了训练过程并提高了模型处理长距离依赖的能力。</p>
<p> Transformer 的四个核心组件：自注意力机制、多头注意力、位置编码和前馈网络。</p>
<h3 id="1-自注意力机制（Self-Attention）"><a href="#1-自注意力机制（Self-Attention）" class="headerlink" title="1. 自注意力机制（Self-Attention）"></a>1. 自注意力机制（Self-Attention）</h3><p>注意力机制（attention）是人工神经网络中一种模仿认知注意力的技术。这种机制可以增强神经网络输入数据中某些部分的权重，同时减弱其他部分的权重，以此将网络的关注点聚焦于数据中最重要的小部分。数据中哪些部分比其他部分更重要取决于上下文。可以通过梯度下降法对注意力机制进行训练。</p>
<blockquote>
<p><strong>例子</strong>：想象一下你正在读一本关于历史的书，遇到了句子：“当王后死后，国王也很快去世。”在理解“国王”这个词时，你的大脑会特别关注“王后”，因为这个词与“国王”的状态密切相关。自注意力机制就是模拟这种在处理每个词时，评估其与句子中其他词的关系并加以利用的能力。</p>
</blockquote>
<h3 id="2-多头注意力（Multi-Head-Attention）"><a href="#2-多头注意力（Multi-Head-Attention）" class="headerlink" title="2. 多头注意力（Multi-Head Attention）"></a>2. 多头注意力（Multi-Head Attention）</h3><blockquote>
<p><strong>例子</strong>：假设你正在组织一个聚会，需要考虑地点、食物和音乐等多个方面。你的大脑会同时处理这些信息，但从不同的角度。地点可能是你从交通方便性角度考虑的，食物可能是从参与者口味偏好考虑的，音乐则是从氛围烘托的角度。多头注意力类似地同时从多个“角度”或“子空间”来处理信息，有助于捕获句子或数据的多方面特性。</p>
</blockquote>
<h3 id="3-位置编码（Positional-Encoding）"><a href="#3-位置编码（Positional-Encoding）" class="headerlink" title="3. 位置编码（Positional Encoding）"></a>3. 位置编码（Positional Encoding）</h3><blockquote>
<p><strong>例子</strong>：想象你正在排队买咖啡。即使闭上眼睛，你也能通过听声音知道大致是哪个顾客在点单，因为你知道他们在说话时的顺序。位置编码的作用类似于这种对顺序感知的机制，它帮助 Transformer 模型理解单词在句子中的位置，即使它处理的是一组单词，而不是一个接一个的单词。</p>
</blockquote>
<h3 id="4-前馈网络（Feed-Forward-Networks）"><a href="#4-前馈网络（Feed-Forward-Networks）" class="headerlink" title="4. 前馈网络（Feed-Forward Networks）"></a>4. 前馈网络（Feed-Forward Networks）</h3><blockquote>
<p><strong>例子</strong>：假设你在一家快餐店工作，对每个客户你都要重复同样的几个步骤：接单、制作、交付。无论前一个订单是什么，处理过程基本相同。在 Transformer 中，前馈网络就是在自注意力结构后对每个位置输出相同操作的网络部分，这一处理过程对于序列中的每个元素都是独立的，类似于你对待每个快餐订单的方式。</p>
</blockquote>
<p>通过上述例子，可以看出 Transformer 的这些核心组件各自独立又相互配合，有效地提升了模型对序列数据的处理能力，特别是在理解和生成语言文本方面的应用。</p>
<div style="text-align: center;">
  <img src="/2024/12/23/AI%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/AI基本概念\Transformer.png" width="40%" alt="机器学习算法">
</div>

<h2 id="12-BERT"><a href="#12-BERT" class="headerlink" title="12.BERT"></a>12.BERT</h2><p>BERT（Bidirectional Encoder Representations from Transformers）是一种基于 Transformer 模型的深度学习技术，用于自然语言处理。BERT 的主要创新之一是它的双向训练，即同时考虑文本中每个词的左侧和右侧上下文。这样的设计使得 BERT 在理解文本的复杂语义方面表现出色。</p>
<h3 id="理解-BERT-的关键组件："><a href="#理解-BERT-的关键组件：" class="headerlink" title="理解 BERT 的关键组件："></a>理解 BERT 的关键组件：</h3><h4 id="1-基于-Transformer-的架构："><a href="#1-基于-Transformer-的架构：" class="headerlink" title="1. 基于 Transformer 的架构："></a>1. <strong>基于 Transformer 的架构</strong>：</h4><p>BERT 接纳了 Transformer 模型中的多头自注意力和位置编码技术，利用这些技术捕获词与词之间的关系，并保持词序信息。不过，BERT 仅使用了 Transformer 的编码器部分（不使用解码器）。</p>
<h4 id="2-双向上下文理解："><a href="#2-双向上下文理解：" class="headerlink" title="2. 双向上下文理解："></a>2. <strong>双向上下文理解</strong>：</h4><p>打个比方，如果你在看一个电影的某个片段时，理解情节不仅要看这个片段之前发生了什么，还要知道后面的情节。BERT 通过双向性（同时看向文本的前后文），比传统单向模型（只从左到右或只从右到左处理文本）更好地理解每个词的含义。</p>
<h4 id="3-预训练和微调："><a href="#3-预训练和微调：" class="headerlink" title="3. 预训练和微调："></a>3. <strong>预训练和微调</strong>：</h4><ul>
<li><strong>预训练</strong>：首先，BERT 在一个庞大的文本库（如维基百科）上进行训练，学习文本中的语言规律。这个阶段的学习任务包括“遮蔽语言模型”（Masked Language Model, MLM）和“下一个句子预测”（Next Sentence Prediction, NSP）。在 MLM 任务中，BERT 随机遮住句中的某些词，尝试预测它们；在 NSH 任务中，BERT 尝试预测第二个句子是否是第一个句子的合理后续。</li>
<li><strong>微调</strong>：预训练完成后，BERT 可以通过额外的训练适应具体任务，比如情感分析、问答回答等。在这一阶段，BERT 结合少量针对特定任务的数据，调整其参数以更好地完成该任务。</li>
</ul>
<h4 id="例子：-10"><a href="#例子：-10" class="headerlink" title="例子："></a>例子：</h4><p>假设你使用 BERT 进行电影评论情感分析（正面或负面评价）。在预训绘时，BERT 学习了大量文本数据，对语言有了广泛的理解。然后，在微调阶段，你提供具体的电影评论数据，教 BERT 学习如何基于评论文本判断情感倾向。通过这样的训练，BERT 能够根据评论中的词及其上下文，理解评论的整体情绤并做出判断。</p>
<p>总之，BERT 的强大之处在于其双向上下文理解能力和灵活的预训练与微调策略，这让它在许多自然语言处理任务中都取得了革命性的进展。</p>
<h2 id="13-GPT（生成式预训练）"><a href="#13-GPT（生成式预训练）" class="headerlink" title="13.GPT（生成式预训练）"></a>13.GPT（生成式预训练）</h2><p>GPT（Generative Pre-trained Transformer）是一种先进的自然语言处理模型，它能生成类似于人类写作的文本。这个名字的每个部分都代表了它的独特功能和结构。让我们逐步解释每个部分，并通过简单的语言和例子来帮助你理解。</p>
<p><strong>生成式</strong>意味着这个模型可以生成内容。这与那些只能进行分类或预测的模型不同，GPT可以创造出全新的句子、段落，甚至整篇文章。</p>
<p><strong>例子：</strong></p>
<ul>
<li><strong>应用</strong>：写作助手，生成完整的文章或故事回应用户的提示。</li>
<li><strong>简单解释</strong>：你给模型一个句子开头（如“从前，有一个勇敢的骑士”），模型可以继续生成下面的情节。</li>
</ul>
<h3 id="预训练（Pre-trained）"><a href="#预训练（Pre-trained）" class="headerlink" title="预训练（Pre-trained）"></a>预训练（Pre-trained）</h3><p><strong>预训练</strong>指的是在大量文本数据上预先训练模型。这使模型在开始应用特定任务时已经有了丰富的语言知识和理解能力。</p>
<h4 id="例子：-11"><a href="#例子：-11" class="headerlink" title="例子："></a>例子：</h4><ul>
<li><strong>应用</strong>：对话系统，回答各种问题。</li>
<li><strong>简单解释</strong>：模型在大规模的书籍、网站和文章等数据集上进行了初步学习，所以它已经理解了很多关于语言的结构和用法。</li>
</ul>
<h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><p><strong>Transformer</strong>是一种神经网络结构，特别适用于处理自然语言。它擅长捕捉文本中的上下文关系，并行处理效率高。</p>
<h4 id="例子：-12"><a href="#例子：-12" class="headerlink" title="例子："></a>例子：</h4><ul>
<li><strong>应用</strong>：翻译系统，将文本从一种语言翻译成另一种。</li>
<li><strong>简单解释</strong>：传统神经网络可能依赖于顺序处理文本，而Transformer可以同时处理一句话中的所有词，这让它在理解复杂文本时非常高效。</li>
</ul>
<h3 id="综合例子：-1"><a href="#综合例子：-1" class="headerlink" title="综合例子："></a>综合例子：</h3><h4 id="使用GPT生成故事"><a href="#使用GPT生成故事" class="headerlink" title="使用GPT生成故事"></a>使用GPT生成故事</h4><p>假设你想要生成一个小故事。你给模型一个开头：</p>
<p><strong>输入：</strong> “在一个遥远的村庄里，有一个年轻的女孩，她发现了一本神秘的旧书。”</p>
<p><strong>生成：</strong><br>GPT可以继续这个开头，写出下面的内容：<br>“书中记载着一个失落的宝藏的位置。一天晚上，月光照进她的房间，她决定跟随线索去寻宝。随着她深入森林，她遇到了各种奇怪的生物，每一个都对她的旅程产生了重要的影响……”</p>
<h3 id="总结：-2"><a href="#总结：-2" class="headerlink" title="总结："></a>总结：</h3><ol>
<li><strong>生成式（Generative）</strong>：模型可以生成新的文本内容。<ul>
<li><strong>简单解释</strong>：给句子开头，模型能继续写故事。</li>
</ul>
</li>
<li><strong>预训练（Pre-trained）</strong>：模型在大量文本上进行了初步训练。<ul>
<li><strong>简单解释</strong>：模型已从大量书籍和文章中学习了语言知识。</li>
</ul>
</li>
<li><strong>Transformer</strong>：一种高效的神经网络结构，擅长处理文本。<ul>
<li><strong>简单解释</strong>：模型能同时理解一句话中的所有词，提高了理解效率。</li>
</ul>
</li>
</ol>
<p>通过这些关键特性，GPT可以在写作、对话、翻译等多种自然语言处理任务中发挥极大的作用，为用户提供智能而流畅的文本生成体验。大语言模型（Large Language Model, LLM）是指具有大量参数并经过大规模数据训练的自然语言处理模型。它们能够执行多种语言任务，如回答问题、生成文本、翻译语言等。</p>
<p>以下是对“大语言模型”的简单解释和举一些易懂的例子：</p>
<h2 id="14-向量数据库"><a href="#14-向量数据库" class="headerlink" title="14.向量数据库"></a>14.向量数据库</h2><p>在人工智能（AI）领域，特别是在处理自然语言或图像等数据时，经常需要将原始数据转换成向量形式。这些向量通常称为特征向量，它们是原始数据的数值表示，可以用于各种机器学习模型的训练和预测。为了高效管理和检索这些向量，我们会使用向量数据库。</p>
<h3 id="向量数据库的理解："><a href="#向量数据库的理解：" class="headerlink" title="向量数据库的理解："></a>向量数据库的理解：</h3><p>向量数据库是专门设计来存储、管理和检索向量数据的数据库。在传统的数据库中，数据通常以表格形式存储，如一行行的数据记录。而向量数据库则更适合处理形式为多维数组的数据，它们能够支持在这些向量集合上执行复杂的查询，比如寻找与给定向量最相似的向量。</p>
<h3 id="为什么需要向量数据库？"><a href="#为什么需要向量数据库？" class="headerlink" title="为什么需要向量数据库？"></a>为什么需要向量数据库？</h3><ol>
<li><strong>高效检索</strong>：在AI应用如推荐系统或图像识别中，快速找到与输入数据相似的历史数据是很重要的。向量数据库通过优化数据结构，加速这种“最近邻”搜索。</li>
<li><strong>大规模存储</strong>：AI训练和应用中常常涉及到大量的向量数据，传统数据库在处理如此大规模的高维数据时效率不高。向量数据库专为这种需求设计，提供更好的存储解决方案。</li>
<li><strong>动态更新</strong>：在许多应用场景中，向量数据需要不断更新或扩展，向量数据库可以高效处理这些动态变化的数据集。</li>
</ol>
<h3 id="例子说明："><a href="#例子说明：" class="headerlink" title="例子说明："></a>例子说明：</h3><ol>
<li><strong>图像搜索</strong>：在一个在线购物网站上，顾客可以上传一张他们喜欢的衣服的图片，系统将返回看起来类似的产品。每个产品的图片在存入数据库之前，首先被转换成一个特征向量。当顾客上传图片时，系统也同样将这张图片转换为向量，然后在向量数据库中搜索最接近的向量，从而找到并推荐相似的商品。</li>
<li><strong>推荐系统</strong>：在音乐流媒体服务中，为了推荐与你过去喜欢的歌曲类似的新歌曲，系统需要对所有歌曲的音频文件进行分析，将它们转换为特征向量。这些向量储存在向量数据库中，当用户播放某首歌时，系统即检索出与当前歌曲特征向量最相似的其他歌曲向量，实现个性化推荐。</li>
<li><strong>面部识别</strong>：安全系统利用面部识别技术来验证个人身份。系统首先将数据库中每个人的面部图像转换为向量，存储在向量数据库中。当有人尝试进入受保护的场所时，系统把此人的面部图像也转为向量，快速在数据库中寻找匹配项，若找到相似度高的向量，则允许进入。</li>
</ol>
<p>通过上述例子，可以看到向量数据库在处理和检索大量高维数据方面的重要性，它是许多现代 AI 系统能够高效运作的关键技术之一。</p>
<h2 id="15-嵌入（Embeddings）"><a href="#15-嵌入（Embeddings）" class="headerlink" title="15.嵌入（Embeddings）"></a>15.嵌入（Embeddings）</h2><p>嵌入（Embeddings）是一种常用的技术，特别是在自然语言处理（NLP）和机器学习领域中，用于将文本、图像等非数值形式的数据转换成数值向量。这些数值向量可以被计算机更好地理解和处理。</p>
<h3 id="嵌入的基本概念："><a href="#嵌入的基本概念：" class="headerlink" title="嵌入的基本概念："></a>嵌入的基本概念：</h3><p>这些向量不是随机的数字，而是通过学习得到的，它们捕捉并表达了原始数据的重要特性和关系。比如在文本处理中，单词的嵌入向量会捕捉到单词的语法和语义特性。</p>
<h3 id="为什么要使用嵌入？"><a href="#为什么要使用嵌入？" class="headerlink" title="为什么要使用嵌入？"></a>为什么要使用嵌入？</h3><ol>
<li><strong>降维</strong>：原始数据如单词、用户ID或商品ID等可能有成千上万的唯一值。如果直接处理这些数据，需要非常大的空间和计算资源。嵌入能够将这些大规模的分类数据压缩到较小的、连续的数值空间中。</li>
<li><strong>捕获关系</strong>：嵌入通过训练学习数据中的关系，例如在文本中，经常共同出现的单词在向量空间中彼此会更接近。</li>
</ol>
<h3 id="例子说明：-1"><a href="#例子说明：-1" class="headerlink" title="例子说明："></a>例子说明：</h3><ol>
<li><strong>单词嵌入</strong>：<ul>
<li>假设你有三个单词：“狗”，“猫”，“汽车”。在没有嵌入的情况下，这三个词是完全不同的，没法比较它们之间的相似性。但如果经过合适的训练，我们可以得到一个向量空间，其中“狗”和“猫”的向量会因为它们都是宠物而彼此更接近，而和“汽车”则距离较远。</li>
</ul>
</li>
<li><strong>商品嵌入</strong>：<ul>
<li>在推荐系统中，如果用户A喜欢商品x, y, z, 而用户B喜欢商品x, y，通过商品的嵌入向量，我们可以计算出B很可能也会喜欢商品z，从而向B推荐z。</li>
</ul>
</li>
<li><strong>图像嵌入</strong>：<ul>
<li>在面部识别技术中，系统会将每个人的面部图像转换成一个数值向量。当需要验证用户身份时，只需将此时的面部图像也转为向量，然后与数据库中存储的向量进行比较，查看是否匹配。</li>
</ul>
</li>
</ol>
<p>通过嵌入技术，我们可以更有效地处理和分析各种复杂的数据，这在其他形式的机器学习任务中也有广泛的应用。总之，嵌入是将大量复杂的数据点转化为易于操作的数值形式的有效工具。</p>
<p>当然，可以用简单的语言来解释这些机器学习的基本概念和不同类型，并通过一些例子来帮助理解。GPT（Generative Pre-trained Transformer）是一种先进的自然语言处理模型，它能生成类似于人类写作的文本。这个名字的每个部分都代表了它的独特功能和结构。让我们逐步解释每个部分，并通过简单的语言和例子来帮助你理解。</p>
<h2 id="16-LLM（大语言模型）"><a href="#16-LLM（大语言模型）" class="headerlink" title="16.LLM（大语言模型）"></a>16.LLM（大语言模型）</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ol>
<li><strong>规模大（Large）</strong>：<ul>
<li><strong>含义</strong>：模型中包含了大量的参数（通常是数十亿到上百亿个参数），这些参数就像大脑中的纽带，帮助模型理解和生成语言。</li>
<li><strong>简单解释</strong>：大语言模型就像有一个非常庞大和复杂的大脑。</li>
</ul>
</li>
<li><strong>语言（Language）</strong>：<ul>
<li><strong>含义</strong>：模型专门处理自然语言（如英语、中文）。</li>
<li><strong>简单解释</strong>：模型非常擅长理解和生成人类语言，例如写文章、回答问题。</li>
</ul>
</li>
<li><strong>模型（Model）</strong>：<ul>
<li><strong>含义</strong>：模型是通过机器学习技术训练出来的一个系统，根据输入生成合理输出。</li>
<li><strong>简单解释</strong>：模型就像一个非常聪明的机器人，可以根据你说的话或写的字做出反应。</li>
</ul>
</li>
</ol>
<h3 id="例子解释："><a href="#例子解释：" class="headerlink" title="例子解释："></a>例子解释：</h3><ol>
<li><strong>回答问题</strong>：<ul>
<li><strong>实际应用</strong>：你可以问大语言模型任何问题，比如“谁是爱因斯坦？”。</li>
<li><strong>模型反应</strong>：模型会回答，“爱因斯坦是著名的物理学家，以相对论闻名。他获得了1921年诺贝尔物理学奖。”</li>
</ul>
</li>
<li><strong>生成文本</strong>：<ul>
<li><strong>实际应用</strong>：你给出一个开头，比如，“在月光下，一只小猫发现了一颗宝石……”。</li>
<li><strong>模型反应</strong>：模型会继续写下去，比如，“它把宝石藏在自己的窝里，但很快，村里的其他动物都听说了这颗神秘的宝石，纷纷前来寻找。”</li>
</ul>
</li>
<li><strong>翻译语言</strong>：<ul>
<li><strong>实际应用</strong>：你输入一句英文，“Hello, how are you?”。</li>
<li><strong>模型反应</strong>：模型会翻译成中文，“你好，你好吗？”</li>
</ul>
</li>
</ol>
<h3 id="理解大语言模型的关键点："><a href="#理解大语言模型的关键点：" class="headerlink" title="理解大语言模型的关键点："></a>理解大语言模型的关键点：</h3><ol>
<li><strong>大量数据训练</strong>：<ul>
<li><strong>含义</strong>：大语言模型在海量的文本数据上进行训练，这些数据来自互联网、书籍、文章等。</li>
<li><strong>简单解释</strong>：模型从海量的书本和文章中学习，积累了丰富的语言知识。</li>
</ul>
</li>
<li><strong>复杂的结构</strong>：<ul>
<li><strong>含义</strong>：大语言模型拥有深层的神经网络结构，这使它能够理解和生成复杂的语言模式。</li>
<li><strong>简单解释</strong>：模型内有很多“层”，每层都负责处理语言的不同方面，就像一支庞大的团队，各司其职。</li>
</ul>
</li>
</ol>
<h3 id="综合例子：-2"><a href="#综合例子：-2" class="headerlink" title="综合例子："></a>综合例子：</h3><p>假设你要与一个大语言模型聊天，你可以简单地开始对话：</p>
<p><strong>输入</strong>： “我今天感觉很开心，因为我完成了一个重要的项目。”</p>
<p><strong>模型反应</strong>：<br>“大语言模型会理解你表达的内容，并继续对话。它可能会回应：‘听起来你很有成就感！能分享一下你完成的项目是什么吗？’”</p>
<p>通过这个对话的例子，你可以看到大语言模型不仅理解了你的心情（开心），还理解了事件的因果关系（完成了一个项目），并给予相关的回应（询问项目）。这展示了它强大的语言理解和生成能力。</p>
<p>总结起来，大语言模型（Large Language Model）是高度复杂和经过大规模训练的人工智能系统，能够高效地理解和生成自然语言，为人们提供多种文本处理能力。它的主要特点是规模大、处理语言、多功能，像一个非常聪明的机器人助手，可以用语言和你交流。OpenAI是一家致力于开发和推广友好人工智能的研究机构。自成立以来，OpenAI在人工智能领域取得了显著的进展，特别是在自然语言处理（NLP）和生成模型方面。以下是OpenAI的发展简介：</p>
<h2 id="17-Model-Size"><a href="#17-Model-Size" class="headerlink" title="17.Model Size"></a>17.Model Size</h2><p>GPT-3大模型的“175B”指的是模型包含的参数数量，即1750亿（175 billion）个参数。这些参数主要包括权重和偏置，在模型训练过程中通过不断更新来优化模型的性能。</p>
<h3 id="具体解释"><a href="#具体解释" class="headerlink" title="具体解释"></a>具体解释</h3><ol>
<li><strong>参数（Parameters）</strong>：<ul>
<li><strong>定义</strong>：参数是模型中的可调节数值，可以是权重（weights）或偏置（bias）等。它们通过神经网络的层和节点连接起来，决定了输入数据如何被处理。</li>
<li><strong>作用</strong>：在训练过程中，模型通过调整这些参数来最小化预测误差，从而提高在各种任务上的表现。</li>
</ul>
</li>
<li><strong>175B参数（175 billion parameters）</strong>：<ul>
<li><strong>含义</strong>：GPT-3有1750亿个参数。这是一个非常庞大的数目，表明该模型有非常高的容量来学习和理解复杂的数据模式。</li>
<li><strong>性能提升</strong>：如此多的参数使GPT-3在生成文本、回答问题、翻译语言等任务上表现非常出色，因为模型能捕捉到更多的语言细节和复杂的上下文关系。</li>
</ul>
</li>
</ol>
<h3 id="为什么参数数量重要？"><a href="#为什么参数数量重要？" class="headerlink" title="为什么参数数量重要？"></a>为什么参数数量重要？</h3><ol>
<li><strong>更高的表达能力</strong>：<ul>
<li><strong>复杂模式</strong>：更多参数使模型能学习和表示数据中的复杂模式和细节。这对于不同自然语言任务（如文本生成、回答问题、翻译等）非常重要。</li>
</ul>
</li>
<li><strong>改善泛化能力</strong>：<ul>
<li><strong>多样数据适应</strong>：参数量大的模型能够处理并适应更加多样化的数据类型和任务，具有更强的泛用性和鲁棒性。</li>
</ul>
</li>
<li><strong>提升性能</strong>：<ul>
<li><strong>精准预测</strong>：更多参数通常意味着模型能提供更高的预测准确度和生成质量，特别是在应对模棱两可或复杂的语言任务时。</li>
</ul>
</li>
</ol>
<h3 id="例子和类比"><a href="#例子和类比" class="headerlink" title="例子和类比"></a>例子和类比</h3><ol>
<li><strong>类比</strong>：<ul>
<li><strong>模拟人脑</strong>：可以把模型中的参数类比为人脑中的神经元连接，越多的连接（参数）意味着“大脑”可以处理和理解更复杂的信息。</li>
</ul>
</li>
<li><strong>实际应用</strong>：<ul>
<li><strong>文本生成</strong>：GPT-3可以生成流畅、自然的文本段落，从简单对话到复杂文章，几乎可以“模仿”人类的写作风格。</li>
<li><strong>问答系统</strong>：当你问GPT-3复杂问题时，它可以理解问题的上下文并提供合理的回答。</li>
<li><strong>编程助手</strong>：GPT-3可以理解编程语言并生成代码片段，帮助程序员提高编程效率。</li>
</ul>
</li>
</ol>
<h3 id="训练和资源需求"><a href="#训练和资源需求" class="headerlink" title="训练和资源需求"></a>训练和资源需求</h3><ol>
<li><strong>计算资源</strong>：<ul>
<li><strong>高需求</strong>：训练这样一个大模型需要非常强大的计算资源，包括大量的GPU或TPU。这要求强大的硬件支持和大量的电力供应。</li>
</ul>
</li>
<li><strong>时间和成本</strong>：<ul>
<li><strong>耗时</strong>：训练模型需要很长时间，可持续几周甚至几个月。</li>
<li><strong>成本高</strong>：由于硬件和电力消耗巨大，训练和部署大模型的成本也非常高。</li>
</ul>
</li>
</ol>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>GPT-3的“175B”参数代表模型内含有1750亿个可调节参数。这些参数让模型能够学习和理解非常复杂的语言模式，从而在各种自然语言处理任务中表现出色。这种大规模参数模型需要大量的计算资源和时间来训练，同时也带来了巨大的应用潜力和优秀的性能表现。</p>
<h2 id="18-OpenAI-简介"><a href="#18-OpenAI-简介" class="headerlink" title="18.OpenAI 简介"></a>18.OpenAI 简介</h2><h3 id="成立与早期发展"><a href="#成立与早期发展" class="headerlink" title="成立与早期发展"></a>成立与早期发展</h3><p><strong>1. 成立背景:</strong></p>
<ul>
<li><strong>成立时间:</strong> OpenAI于2015年12月由埃隆·马斯克、萨姆·奥特曼、格雷格·布罗克曼、伊利亚·苏茨克维、约翰·舒尔曼和沃伊切赫·扎伦巴等人共同创立。</li>
<li><strong>使命:</strong> OpenAI的使命是确保人工智能（AI）造福全人类，并防止AI技术的滥用。其目标是通过开发安全且强大的AI系统，推动AI技术的进步，同时确保这些技术的使用符合人类的最佳利益。</li>
</ul>
<p><strong>2. 早期研究:</strong></p>
<ul>
<li><strong>强化学习:</strong> OpenAI在早期进行了大量关于强化学习的研究，开发了许多创新算法和工具，如OpenAI Gym，这是一个用于开发和比较强化学习算法的开源平台。</li>
<li><strong>AI安全:</strong> OpenAI还在AI安全性方面进行了深入研究，探索如何确保AI系统的可靠性和透明度。</li>
</ul>
<h3 id="主要突破与模型"><a href="#主要突破与模型" class="headerlink" title="主要突破与模型"></a>主要突破与模型</h3><p><strong>1. GPT系列模型:</strong></p>
<ul>
<li><strong>GPT-1 (2018):</strong> 第一个生成预训练变换器（Generative Pre-trained Transformer, GPT）模型，展示了通过无监督学习进行语言建模的强大潜力。</li>
<li><strong>GPT-2 (2019):</strong> GPT-2是一个更大、更强的语言模型，具有15亿参数。由于其生成高质量文本的能力，OpenAI最初对其进行了限制发布，担心其可能被滥用。</li>
<li><strong>GPT-3 (2020):</strong> GPT-3拥有1750亿参数，是当时最大的语言模型之一。它展示了在各种自然语言处理任务中的卓越性能，并被广泛应用于聊天机器人、内容生成、代码编写等领域。</li>
<li><strong>GPT-4 (2023):</strong> GPT-4进一步提升了模型的规模和性能，成为目前最先进的语言模型之一，能够处理更复杂的任务和生成更自然的文本。</li>
</ul>
<p><strong>2. Codex:</strong></p>
<ul>
<li><strong>Codex (2021):</strong> Codex是基于GPT-3的一个变体，专门用于理解和生成代码。它被集成到GitHub Copilot中，帮助开发者编写代码，提高编程效率。</li>
</ul>
<h3 id="其他重要项目"><a href="#其他重要项目" class="headerlink" title="其他重要项目"></a>其他重要项目</h3><p><strong>1. DALL-E:</strong></p>
<ul>
<li><strong>DALL-E (2021):</strong> DALL-E是一个生成模型，能够根据文本描述生成图像。它展示了将语言模型应用于图像生成的潜力，开辟了新的创意和设计可能性。</li>
</ul>
<p><strong>2. CLIP:</strong></p>
<ul>
<li><strong>CLIP (2021):</strong> CLIP（Contrastive Language-Image Pre-Training）是一个将图像和文本结合的模型，能够理解和生成与文本描述匹配的图像。它在图像分类、对象识别等任务中表现出色。</li>
</ul>
<h3 id="合作与开源"><a href="#合作与开源" class="headerlink" title="合作与开源"></a>合作与开源</h3><p><strong>1. 合作伙伴:</strong></p>
<ul>
<li><strong>微软:</strong> OpenAI与微软建立了战略合作伙伴关系，微软为OpenAI提供了Azure云计算平台，并投资了10亿美元支持OpenAI的发展。双方合作推出了Azure OpenAI服务，使更多企业能够使用OpenAI的技术。</li>
</ul>
<p><strong>2. 开源:</strong></p>
<ul>
<li><strong>开源工具:</strong> OpenAI发布了许多开源工具和库，如OpenAI Gym、OpenAI Baselines等，促进了AI研究社区的合作与交流。</li>
<li><strong>开放研究:</strong> OpenAI致力于开放研究，发布了许多研究论文和技术报告，推动了AI技术的透明性和共享。</li>
</ul>
<h3 id="未来展望"><a href="#未来展望" class="headerlink" title="未来展望"></a>未来展望</h3><p>OpenAI的未来发展方向包括继续提升AI模型的能力和安全性，探索AI在各个领域的应用，并确保AI技术的公平和可靠使用。通过与全球研究社区和行业伙伴的合作，OpenAI致力于实现其使命，使AI技术造福全人类。</p>
<h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><p>OpenAI在人工智能领域取得了显著的进展，特别是在自然语言处理和生成模型方面。通过不断的研究和创新，OpenAI推动了AI技术的发展，并致力于确保这些技术的安全和公平使用。未来，OpenAI将继续探索AI的潜力，为人类社会带来更多的益处。</p>
]]></content>
  </entry>
  <entry>
    <title>HDBSCAN</title>
    <url>/2024/12/11/HDBSCAN/</url>
    <content><![CDATA[<h2 id="1-HDBSCAN算法简介"><a href="#1-HDBSCAN算法简介" class="headerlink" title="1.HDBSCAN算法简介"></a>1.HDBSCAN算法简介</h2><p>DBSCAN(Hierarchical Density-Based Spatial Clustering of Applications with Noise)是一种高效的密度聚类算法,由Campello、Moulavi和Sander于2013年提出。它是DBSCAN算法的扩展版本,通过将DBSCAN转化为层次聚类算法,并使用基于聚类稳定性的技术来提取平面聚类结果，其实HDBSCAN算法是对OPTICS算法的一种改进。</p>
<p>HDBSCAN算法优势：</p>
<ol>
<li>能够发现任意形状的聚类</li>
<li>可以处理不同密度的数据分布</li>
<li>对噪声和异常值具有较强的鲁棒性</li>
<li>参数调整简单直观</li>
</ol>
<p>HDBSCAN算法的具体过程分为一下几步</p>
<ol>
<li>空间变换</li>
<li>构建最小生成树</li>
<li>构建聚类层次结构</li>
<li>压缩聚类树</li>
<li>提取簇</li>
</ol>
<h2 id="2-空间变换"><a href="#2-空间变换" class="headerlink" title="2.空间变换"></a>2.空间变换</h2><ul>
<li><strong>核心距离（core-distance）</strong>：使样本x成为核心点的最小邻域半径称为x的核心距离</li>
<li><strong>互达距离</strong>：</li>
</ul>
<script type="math/tex; mode=display">
d_{mreach − k} ( a ,  b ) = max \{ core_k(a),core_k(b),d(a,b)\}</script><p><strong>在这个度量下，密集点（具有低核心距离）之间的距离保持不变，但稀疏的点与其他点的距离被拉远到用core距离来计算。</strong></p>
<div style="text-align: center;">
  <img src="/2024/12/11/HDBSCAN/HDBSCAN1.png" width="60%" alt="描述性文本">
</div>

<p>蓝点和绿点的互达距离，就是绿点的核心距离（绿线）</p>
<div style="text-align: center;">
  <img src="/2024/12/11/HDBSCAN/HDBSCAN2.png" width="60%" alt="描述性文本">
</div>

<p>红点和绿点的互达距离，就是他们两个点之间的距离（黄线）</p>
<h2 id="3-建立最小生成树"><a href="#3-建立最小生成树" class="headerlink" title="3.建立最小生成树"></a>3.建立最小生成树</h2><p>距离度量： <strong>互达距离</strong> </p>
<p>可将数据看作一个加权图，其中数据点为顶点，任意两点之间的边的权重为这些点之间的互达距离。考虑一个距离阈值，从高开始逐步降低，删除任何超过阈值的边，对图像进行分裂。最终图的变化过程：从完全连接到不完全连接。逐步减小阈值去分裂图的方法时间复杂度较高。正确的做法是找一个最小边集合，这样从集合中删除任何边都会导致图分裂。这个最小边的集合就是图的最小树。可以通过 <a href="https://blog.csdn.net/ACM_hades/article/details/79029253">Prim 算法</a> 非常有效地构建最小生成树树，如下图所示：</p>
<div style="text-align: center;">
  <img src="/2024/12/11/HDBSCAN/HDBSCAN3.png" width="60%" alt="描述性文本">
</div>

<h2 id="4-构建聚类层次结构"><a href="#4-构建聚类层次结构" class="headerlink" title="4.构建聚类层次结构"></a>4.构建聚类层次结构</h2><p>给定最小生成树，下一步是将其转换为图分裂的层次结构</p>
<ol>
<li>第一步：将树中的所有边按照距离递增排序</li>
<li>第二步：然后依次选取每条边，将边的链接的两个子图进行合并。（类似于层次聚类的思路）</li>
</ol>
<p>以下得到的树又称为聚类树，此时如果和层次聚类一样，设置一条distance的阈值，就可以将红线下面最近的节点作为聚类的一个类，而红线上面的聚起来的都是散点。如何得到阈值？？</p>
<p>但是这样得到的聚类结果，会有很多有很少量节点的簇，我们需要压缩聚类树。</p>
<div style="text-align: center;">
  <img src="/2024/12/11/HDBSCAN/HDBSCAN4.png" width="60%" alt="描述性文本">
</div>
<div style="text-align: center;">
  <img src="/2024/12/11/HDBSCAN/HDBSCAN5.png" width="60%" alt="描述性文本">
</div>

<p>上图是一个二叉树结构，每个节点代表的是一个样本子集，最上面的根节点代表的是所有样本点，每个节点的两条边代表的是当前节点的分裂，每次分裂都是去掉最小生成树的一边，从上到下，相当于选择最大的边进行分裂，每次分裂都对应着一个距离。</p>
<h2 id="5-压缩聚类树"><a href="#5-压缩聚类树" class="headerlink" title="5.压缩聚类树"></a>5.<strong>压缩聚类树</strong></h2><p>通过压缩聚类树，我们可以得到一棵<strong>拥有少量节点的聚类树（如上）</strong><br>簇抽取的第一步是将庞大而复杂的聚类树压缩到一个更小的树中，其实质就是去掉散点。<br><strong>最小簇大小：每个簇中样本数的最小值，作为HDBSCAN的一个参数</strong><br>压缩聚类树步骤：</p>
<ul>
<li>第一步：确定最小簇大小；</li>
<li><p>第二步：自上而下遍历聚类树，并在每个节点分裂时，看分裂产生的两个样本子集的样本数是否大于最小簇大小</p>
<ul>
<li>如果左右子节点有一个子节点的样本数少于最小簇大小，我们将直接将该节点删除，并且另一个子节点保留父节点的身份；</li>
<li>如果两个子节点中的样本数均小于最小簇大小，那么将其两个子节点都删除，即当前节点不再向下分裂</li>
<li>如果两个子节点的样本数均大于最小簇大小，则进行正常分裂，保持原聚类树不变。<br><strong>（删除的点都是HDBSCAN视为的噪点）</strong></li>
</ul>
</li>
<li><p>在遍历了整个聚类树之后，我们最终得到了一个 <strong>拥有少量节点的聚类树</strong></p>
</li>
</ul>
<div style="text-align: center;">
  <img src="/2024/12/11/HDBSCAN/HDBSCAN6.png" width="60%" alt="描述性文本">
</div>

<p>用线的宽度来表示簇中的点数。由于有节点的删除宽度随逐渐变小</p>
<p>图中 λ 为距离的倒数，即：</p>
<script type="math/tex; mode=display">λ=1/distance</script><h2 id="6-提取簇"><a href="#6-提取簇" class="headerlink" title="6.提取簇"></a>6.<strong>提取簇</strong></h2><p>从压缩的聚类树种提取聚类的簇，为压缩聚类树的每个节点打上一个类标签</p>
<p>提取簇的一个原则是：某个节点属于某一个簇，那么他的子节点都属于这个簇</p>
<ul>
<li>经过聚类树的压缩操作，树中已经没有了散点，现在的任务只是将比较相近的节点合并到一簇中去，最后选择的簇能够有更好的 <strong>稳定性。</strong></li>
<li><p>如何来定义树中节点的稳定性呢？</p>
<ul>
<li>先定义一个 λ  ，它是距离的倒数：<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="15.022ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 6639.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="mo" transform="translate(860.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mn" transform="translate(1916.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2416.6,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"/></g></g><g data-mml-node="mi" transform="translate(2916.6,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mi" transform="translate(3436.6,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(3781.6,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"/></g><g data-mml-node="mi" transform="translate(4250.6,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mi" transform="translate(4611.6,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="mi" transform="translate(5140.6,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(5740.6,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"/></g><g data-mml-node="mi" transform="translate(6173.6,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"/></g></g></g></svg></mjx-container></li>
<li>对于树中的某个节点定义两个量： <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="4.966ex" height="1.927ex" role="img" focusable="false" viewbox="0 -694 2194.8 851.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"/></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(774,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(1225,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mi" transform="translate(1586,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"/></g></g></g></g></g></svg></mjx-container> ，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="5.429ex" height="1.927ex" role="img" focusable="false" viewbox="0 -694 2399.8 851.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mi" transform="translate(520,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"/></g><g data-mml-node="mi" transform="translate(986,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="mi" transform="translate(1515,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mi" transform="translate(1876,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"/></g></g></g></g></g></svg></mjx-container><br><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="4.966ex" height="1.927ex" role="img" focusable="false" viewbox="0 -694 2194.8 851.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"/></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(774,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(1225,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mi" transform="translate(1586,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"/></g></g></g></g></g></svg></mjx-container> ：分裂产生当前节点时，对应断开边长度的倒数。<br><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="5.429ex" height="1.927ex" role="img" focusable="false" viewbox="0 -694 2399.8 851.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mi" transform="translate(520,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"/></g><g data-mml-node="mi" transform="translate(986,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="mi" transform="translate(1515,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mi" transform="translate(1876,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"/></g></g></g></g></g></svg></mjx-container>：当前节点被分裂成两个子结点时，对应断开边长度的倒数。<br>根据定义有:  <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="13.412ex" height="1.927ex" role="img" focusable="false" viewbox="0 -694 5928.1 851.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"/></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(774,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(1225,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mi" transform="translate(1586,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"/></g></g></g><g data-mml-node="mo" transform="translate(2472.5,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"/></g><g data-mml-node="msub" transform="translate(3528.3,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mi" transform="translate(520,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"/></g><g data-mml-node="mi" transform="translate(986,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="mi" transform="translate(1515,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mi" transform="translate(1876,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"/></g></g></g></g></g></svg></mjx-container></li>
<li>对于每个节点中每个样本点 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.138ex" height="1.439ex" role="img" focusable="false" viewbox="0 -442 503 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g></g></g></svg></mjx-container> 定义一个量<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="2.311ex" height="2.22ex" role="img" focusable="false" viewbox="0 -694 1021.7 981.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g></g></g></g></svg></mjx-container><br><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="2.311ex" height="2.22ex" role="img" focusable="false" viewbox="0 -694 1021.7 981.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g></g></g></g></svg></mjx-container> 表示：样本点 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.138ex" height="1.439ex" role="img" focusable="false" viewbox="0 -442 503 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g></g></g></svg></mjx-container> 因为分裂离开该节点时，对应断开边长度的倒数。当前节点分裂使得样本 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.138ex" height="1.439ex" role="img" focusable="false" viewbox="0 -442 503 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g></g></g></svg></mjx-container> 离开当前节点有两种情况：<ul>
<li>当前节点分裂出的右儿子中有一个子结点的样本数少于最小族大小，这时我们是直间将该节点删除，并且另一个子节点保留父节点的身份，而并且样本 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.138ex" height="1.439ex" role="img" focusable="false" viewbox="0 -442 503 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g></g></g></svg></mjx-container> 在被删掉的子结点中，即样本 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.138ex" height="1.439ex" role="img" focusable="false" viewbox="0 -442 503 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g></g></g></svg></mjx-container> 是散点，这时 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="18.741ex" height="2.22ex" role="img" focusable="false" viewbox="0 -694 8283.4 981.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"/></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(774,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(1225,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mi" transform="translate(1586,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"/></g></g></g><g data-mml-node="mo" transform="translate(2472.5,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"/></g><g data-mml-node="msub" transform="translate(3528.3,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g></g><g data-mml-node="mo" transform="translate(4827.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"/></g><g data-mml-node="msub" transform="translate(5883.6,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mi" transform="translate(520,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"/></g><g data-mml-node="mi" transform="translate(986,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="mi" transform="translate(1515,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mi" transform="translate(1876,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"/></g></g></g></g></g></svg></mjx-container></li>
<li>当前节点分裂出的两个子结点中的样本数都大于最小族大小，这时我们进行正常分裂，这样样本 p p <em>p</em> 进入当前节点的一个子结点。<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="10.758ex" height="2.22ex" role="img" focusable="false" viewbox="0 -694 4755.1 981.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g></g><g data-mml-node="mo" transform="translate(1299.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="msub" transform="translate(2355.2,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mi" transform="translate(520,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"/></g><g data-mml-node="mi" transform="translate(986,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="mi" transform="translate(1515,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g><g data-mml-node="mi" transform="translate(1876,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"/></g></g></g></g></g></svg></mjx-container></li>
</ul>
</li>
<li><p>现在我们将每个 <strong>节点的稳定性</strong> 定义为：</p>
<script type="math/tex; mode=display">
 s_{c l u s t e r}  =   \sum\limits_{p \in \text{cluster}} (\lambda_p - \lambda_{\text{death}})</script><p>稳定性越大说明该节点中的散点越少。hdbscan需要找到最大<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -2.59ex;" xmlns="http://www.w3.org/2000/svg" width="18.762ex" height="4.287ex" role="img" focusable="false" viewbox="0 -750 8292.8 1894.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="munder"><g data-mml-node="mo" transform="translate(909.9,0)"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"/></g><g data-mml-node="TeXAtom" transform="translate(0,-907.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g><g data-mml-node="mo" transform="translate(503,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"/></g><g data-mml-node="mtext" transform="translate(1170,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"/><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(444,0)"/><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(722,0)"/><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(1278,0)"/><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1672,0)"/><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2061,0)"/><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(2505,0)"/></g></g></g><g data-mml-node="mo" transform="translate(2875.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="msub" transform="translate(3264.8,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g></g><g data-mml-node="mo" transform="translate(4508.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/></g><g data-mml-node="msub" transform="translate(5508.9,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"/><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(556,0)"/><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1000,0)"/><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1500,0)"/><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1889,0)"/></g></g></g><g data-mml-node="mo" transform="translate(7903.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g></g></g></svg></mjx-container>的分裂簇方法，同时需要满足最小簇类大小。<br><strong>提取簇步骤</strong>：</p>
</li>
</ul>
</li>
<li><strong>第一步</strong> ：初始化族<ul>
<li>将压缩聚类树的每个叶节点都选定为某个簇。</li>
</ul>
</li>
<li><strong>第二步</strong> ： <strong>自下而上遍历遍历整棵树</strong> ，并且每一步进行下面操作：<ul>
<li>如果当前节点的稳定性小于两个子结点的稳定性总和，那么我们将该节点的稳定性设置为其子节点的稳定性之和</li>
<li><strong>如果当前节点的稳定性大于两个子结点的稳定性总和，那么将当前节点定为某个簇，并且删除所有子节点。</strong></li>
</ul>
</li>
<li>我们可以通过这个算法选择上面压缩聚类树的聚类，得到下面结果：</li>
</ul>
<div style="text-align: center;">
  <img src="/2024/12/11/HDBSCAN/HDBSCAN7.png" width="60%" alt="描述性文本">
</div>

<p>不同颜色的圈表示不同的族，上图将样本分为三个簇。</p>
<p>我们将聚类产生的散点(即压缩聚类树时删除的节点)标为-1类，</p>
<p>相比DBSCAN算法HDBSCAN主要做了如下几个优化：</p>
<ol>
<li>定义了一种衡量两个点互相间的距离的方式（<strong>互达距离）</strong></li>
<li>使用最小生成树构建点与点之间的层次数模型，引入<a href="https://zhida.zhihu.com/search?content_id=102517831&amp;content_type=Article&amp;match_order=1&amp;q=%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB&amp;zhida_source=entity">层次聚类</a>思想，同时对最小生成树剪枝的最小子树做了限制，主要是为了控制生成的类簇不要过小</li>
<li>定义了一种叫stability的分裂度量方式，hdbscan需要找到最大<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -2.59ex;" xmlns="http://www.w3.org/2000/svg" width="18.762ex" height="4.287ex" role="img" focusable="false" viewbox="0 -750 8292.8 1894.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="munder"><g data-mml-node="mo" transform="translate(909.9,0)"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"/></g><g data-mml-node="TeXAtom" transform="translate(0,-907.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g><g data-mml-node="mo" transform="translate(503,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"/></g><g data-mml-node="mtext" transform="translate(1170,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"/><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(444,0)"/><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(722,0)"/><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(1278,0)"/><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1672,0)"/><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2061,0)"/><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(2505,0)"/></g></g></g><g data-mml-node="mo" transform="translate(2875.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="msub" transform="translate(3264.8,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g></g><g data-mml-node="mo" transform="translate(4508.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/></g><g data-mml-node="msub" transform="translate(5508.9,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"/><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(556,0)"/><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1000,0)"/><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1500,0)"/><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1889,0)"/></g></g></g><g data-mml-node="mo" transform="translate(7903.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g></g></g></svg></mjx-container>的分裂簇方法，同时需要满足最小簇类大小。</li>
</ol>
]]></content>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>问题记录</title>
    <url>/2024/10/28/errors/</url>
    <content><![CDATA[<h2 id="1-osgearth-ttf-file-not-handled"><a href="#1-osgearth-ttf-file-not-handled" class="headerlink" title="1. osgearth .ttf: file not handled"></a>1. osgearth .ttf: file not handled</h2><p>在使用osgearth时，发生错误如下：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="title class_">Error</span> reading file <span class="attr">C</span>:<span class="regexp">/WINDOWS/</span>fonts\<span class="title class_">CascadiaCode</span>.<span class="property">ttf</span>: file not handled</span><br></pre></td></tr></table></figure>
<p>经查阅可知，osg的读写字体文件的插件dll找不到了。<br><strong>解决方法</strong></p>
<ol>
<li>添加环境变量<br>在系统环境变量中添加osg 的path路径</li>
<li>添加配置文件<br>在每个osg工程中配置osg头文件lib和dll以及plugins<br><img src="../images/errorConf.png" alt="t"></li>
</ol>
]]></content>
  </entry>
</search>
